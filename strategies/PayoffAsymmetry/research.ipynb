{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Payoff Asymmetry: BTC-Standard Classification (with Funding & OI)\n",
                "This notebook treatments: **Relative Value** + **Microstructure (Funding, OI)**.\n",
                "We aim to predict the probability of a high payoff asymmetry ($Y > 0.1$)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime, timedelta\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import roc_auc_score, precision_recall_curve, confusion_matrix, classification_report\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-muted')\n",
                "sns.set_palette(\"viridis\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Constants & Data Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = \"/Users/chenzhao/Documents/lean_workspace/data/cryptofuture/binance/minute\"\n",
                "EXTRA_DIR = \"/Users/chenzhao/Documents/lean_workspace/data/cryptofuture/binance/extra\"\n",
                "START_DATE = datetime(2025, 1, 1)\n",
                "END_DATE = datetime(2026, 1, 31)\n",
                "\n",
                "TICKERS = [\n",
                "    \"ethusdt\", \"bnbusdt\", \"solusdt\", \"xrpusdt\",\n",
                "    \"dogeusdt\", \"adausdt\", \"avaxusdt\", \"dotusdt\", \"linkusdt\",\n",
                "    \"maticusdt\", \"ltcusdt\", \"uniusdt\", \"atomusdt\", \"etcusdt\",\n",
                "    \"filusdt\", \"aptusdt\", \"nearusdt\", \"arbusdt\", \"opusdt\",\n",
                "    \"injusdt\", \"suiusdt\", \"tiausdt\", \"seiusdt\", \"stxusdt\",\n",
                "    \"imxusdt\", \"runeusdt\", \"aaveusdt\", \"mkrusdt\", \"ldousdt\"\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Shared Data Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_ticker_data(ticker, start_date, end_date):\n",
                "    ticker_dir = os.path.join(DATA_DIR, ticker)\n",
                "    if not os.path.exists(ticker_dir): return pd.DataFrame()\n",
                "    all_dfs = []\n",
                "    for f in sorted(os.listdir(ticker_dir)):\n",
                "        if not f.endswith(\"_trade.zip\"): continue\n",
                "        date_str = f.split(\"_\")[0]\n",
                "        try:\n",
                "            file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
                "            if start_date <= file_date <= end_date:\n",
                "                df = pd.read_csv(os.path.join(ticker_dir, f), header=None, compression='zip')\n",
                "                df.columns = ['ms', 'open', 'high', 'low', 'close', 'volume']\n",
                "                df['time'] = file_date + pd.to_timedelta(df['ms'], unit='ms')\n",
                "                df.set_index('time', inplace=True)\n",
                "                all_dfs.append(df[['high', 'low', 'close', 'volume']])\n",
                "        except: continue\n",
                "    if not all_dfs: return pd.DataFrame()\n",
                "    return pd.concat(all_dfs).sort_index().drop_duplicates()\n",
                "\n",
                "def load_extra_data(ticker):\n",
                "    path = os.path.join(EXTRA_DIR, f\"{ticker}_extra.csv\")\n",
                "    if not os.path.exists(path): return pd.DataFrame()\n",
                "    df = pd.read_csv(path)\n",
                "    df['time'] = pd.to_datetime(df['time'])\n",
                "    df.set_index('time', inplace=True)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dataset Construction (Relative + Microstructure)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading BTC reference data (OHLC + Funding)...\")\n",
                "btc_raw = load_ticker_data(\"btcusdt\", START_DATE, END_DATE)\n",
                "btc_extra = load_extra_data(\"btcusdt\")\n",
                "\n",
                "samples = []\n",
                "for ticker in TICKERS:\n",
                "    print(f\"Processing {ticker}...\", end='\\r')\n",
                "    asset_raw = load_ticker_data(ticker, START_DATE, END_DATE)\n",
                "    asset_extra = load_extra_data(ticker)\n",
                "    if asset_raw.empty or asset_extra.empty: continue\n",
                "    \n",
                "    # 1. Relative OHLC\n",
                "    df = asset_raw.join(btc_raw, rsuffix='_btc', how='inner')\n",
                "    df['close_rel'] = df['close'] / df['close_btc']\n",
                "    df['high_rel'] = df['high'] / df['low_btc']\n",
                "    df['low_rel'] = df['low'] / df['high_btc']\n",
                "    df['log_ret_rel'] = np.log(df['close_rel'] / df['close_rel'].shift(1))\n",
                "    \n",
                "    # 2. Merge Extra Features (Forward Fill to Hour)\n",
                "    # Note: Funding is usually 8h, we'll ffill it.\n",
                "    ex_df = asset_extra.join(btc_extra, rsuffix='_btc', how='outer').sort_index().ffill()\n",
                "    ex_df['rel_funding'] = ex_df['fundingRate'] - ex_df['fundingRate_btc']\n",
                "    \n",
                "    # Resample everything to Hour for feature construction\n",
                "    hourly_idx = df.resample('1H').last().dropna().index\n",
                "    \n",
                "    for ts in hourly_idx:\n",
                "        try:\n",
                "            w1h = df.loc[ts - timedelta(hours=1):ts]\n",
                "            w12h = df.loc[ts - timedelta(hours=12):ts]\n",
                "            w24h = df.loc[ts - timedelta(hours=24):ts]\n",
                "            if len(w1h) < 40 or len(w12h) < 500: continue\n",
                "            \n",
                "            price_rel = w1h['close_rel'].iloc[-1]\n",
                "            sigma_rel = w1h['log_ret_rel'].std() + 1e-6\n",
                "            \n",
                "            # -- Price Features (Relative) --\n",
                "            Rel_HighPressure = (w24h['high_rel'].max() - price_rel) / (price_rel * sigma_rel)\n",
                "            Rel_Momentum = (price_rel - w12h['close_rel'].iloc[0]) / (w12h['close_rel'].iloc[0] * w12h['log_ret_rel'].std() + 1e-6)\n",
                "            Rel_VolRatio = (w12h[w12h['log_ret_rel'] < 0]['log_ret_rel'].std() or 0) / (w12h[w12h['log_ret_rel'] > 0]['log_ret_rel'].std() + 1e-6)\n",
                "            \n",
                "            # -- Microstructure Features --\n",
                "            # Get latest available metrics at or before ts\n",
                "            cur_ex = ex_df.loc[:ts].iloc[-1] if not ex_df.loc[:ts].empty else None\n",
                "            if cur_ex is None: continue\n",
                "            \n",
                "            Ext_Funding = cur_ex['fundingRate']\n",
                "            Ext_RelFunding = cur_ex['rel_funding']\n",
                "            Ext_OI = cur_ex['openInterest']\n",
                "            # OI Change (Last 12h if available)\n",
                "            prev_ex = ex_df.loc[:ts - timedelta(hours=12)].iloc[-1] if not ex_df.loc[:ts - timedelta(hours=12)].empty else cur_ex\n",
                "            Ext_OIChange = (cur_ex['openInterest'] - prev_ex['openInterest']) / (prev_ex['openInterest'] + 1e-6)\n",
                "            \n",
                "            # -- Label (Classification) --\n",
                "            f_end = ts + timedelta(hours=12)\n",
                "            if f_end > df.index[-1]: continue\n",
                "            f_period = df.loc[ts + timedelta(minutes=1):f_end]\n",
                "            if f_period.empty: continue\n",
                "            y_actual = np.log((price_rel - f_period['low_rel'].min()) / (f_period['high_rel'].max() - price_rel + 1e-6) + 1e-6)\n",
                "            label = 1 if y_actual > 0.1 else 0\n",
                "            \n",
                "            samples.append({\n",
                "                'ticker': ticker, 'time': ts, 'label': label, 'y_value': y_actual,\n",
                "                'Rel_HighP': Rel_HighPressure, 'Rel_Mom': Rel_Momentum, 'Rel_VolR': Rel_VolRatio,\n",
                "                'Funding': Ext_Funding, 'RelFunding': Ext_RelFunding, 'OI_Change': Ext_OIChange\n",
                "            })\n",
                "        except: continue\n",
                "\n",
                "dataset = pd.DataFrame(samples).dropna()\n",
                "print(f\"\\nDone. Dataset size: {len(dataset)} | Target 1 Rate: {dataset['label'].mean():.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Training & Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = dataset.sort_values('time')\n",
                "train_df = dataset[dataset['time'] < datetime(2026, 1, 1)]\n",
                "test_df = dataset[dataset['time'] >= datetime(2026, 1, 1)]\n",
                "\n",
                "X_cols = ['Rel_HighP', 'Rel_Mom', 'Rel_VolR', 'Funding', 'RelFunding', 'OI_Change']\n",
                "model = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
                "model.fit(train_df[X_cols], train_df['label'])\n",
                "\n",
                "test_df['prob'] = model.predict_proba(test_df[X_cols])[:, 1]\n",
                "auc = roc_auc_score(test_df['label'], test_df['prob'])\n",
                "print(f\"OOT ROC AUC: {auc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Diagnostic Plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "importances = pd.Series(model.feature_importances_, index=X_cols).sort_values()\n",
                "importances.plot(kind='barh', title='Feature Importance (Alpha + Microstructure)')\n",
                "plt.show()\n",
                "\n",
                "test_df['prob_q'] = pd.qcut(test_df['prob'], 5, labels=False)\n",
                "test_df.groupby('prob_q')['y_value'].mean().plot(kind='bar', title='Mean Realized Y by Prob Quintile')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}